<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<title>Архітектура комп'ютерів</title>
	<link href="../style/style.css" rel="stylesheet">
	<link rel="shortcut icon" href="../img/favicon.ico" />
	<script src="../js/jquery-3.2.1.min.js"></script>
	<script src="../js/JavaScript.js" type="text/javascript" ></script>
</head>
<body class="body">
	<div class="wrapper clearfix">
		<header class="header">
			<nav class="menu">
				<ul>
					<li><a href="CPU.html">Енциклопедія</a></li>
					<li><a href="index_CPU.html">Побудова ЦП</a></li>
					<li><a href="motherboard.html">Мат. плата</a></li>
					<li><a href="x86.html">X86</a></li>
					<li><a href="index_PG_CPU.html">Програмна модель ЦП</a></li>
				</ul>
				<form>
					<input type="text" id="text-to-find" value="">
					<button type="submit" onclick="javascript: FindOnPage('text-to-find'); return false;" value="Пошук"></button>
				</form>
			</nav>
		</header>
		<main class="content">
			<div class="pad">
				<div class="in-cont-nav">
					<p>Зміст</p>
					<ul>
						<li><a href="#1">1. Вступ</a></li>
						<li><a href="#2">2. Ядро процесора</a></li>
						<li><a href="#2.1" class="mar5">2.1. Принцип роботи ядра процесора</a></li>
						<li><a href="#2.2" class="mar5">2.2. Методи покращення роботи ядра процесора</a></li>
						<li><a href="#2.2.1" class="mar10">2.2.1. Конвеєризація</a></li>
						<li><a href="#2.2.2" class="mar10">2.2.2. Суперскалярність</a></li>
						<li><a href="#2.2.3" class="mar10">2.2.3. Паралельна обробка даних</a></li>
						<li><a href="#2.2.4" class="mar10">2.2.4. Технологія Hyper-threading</a></li>
						<li><a href="#2.2.5" class="mar10">2.2.5. Технологія Turbo Boost.</a></li>
						<li><a href="#2.2.6" class="mar10">2.2.6. Ефективність виконання команд.</a></li>
						<li><a href="#2.3" class="mar5">2.3 Способи зниження енергоспоживання ядра процесора</a></li>
						<li><a href="#3">3. Кеш-пам'ять</a></li>
					</ul>
				</div>
			</div>	
			<div class="main-text">
				<h1>Побудова процесору</h1>
				<p>Процесор - це основний пристрій ЕОМ, що виконує логічні і арифметичні операції, і який здійснює управління всіма компонентами ЕОМ. Процесор являє собою мініатюрну тонку кремнієву пластинку прямокутної форми, на якій розміщується величезна кількість транзисторів, що реалізують всі функції, які виконуються процесором. Кремнієва пластинка - дуже крихкістна, а так як її будь-яке пошкодження призведе до виходу з ладу процесора, то вона поміщається в пластиковий або керамічний корпус.</p>
				<h2><a name="1"></a>1. Вступ</h2> 
				<p>Сучасний процесор - це складний і високотехнологічний пристрій, що включає в себе всі найостанніші досягнення в області обчислювальної техніки і супутніх галузей науки.</p>
				<p>Більшість сучасних процесорів складається з:</p>
				<ul class="ul"><li>одного або декількох ядер, які здійснюють виконання всіх інструкцій;</li><li>декількох рівнів КЕШ-пам'яті (зазвичай, 2 або три рівня), що прискорюють взаємодію процесора з ОЗУ;</li><li>контролера ОЗУ;</li><li>контролера системної шини (DMI, QPI, HT і т.д.);</li></ul>
				<p>І характеризується наступними параметрами:</p>
				<ul class="ul"><li>типом мікроархітектури;</li><li>тактовою частотою;</li><li>набором виконуваних команд;</li><li>кількістю рівнів КЕШ-пам'яті та їх об'ємом;</li><li>типом і швидкістю системної шини;</li><li>розмірами оброблюваних слів;</li><li>наявністю або відсутністю вбудованого контролера пам'яті;</li><li>типом підтримуваної оперативної пам'яті;</li><li>об'ємом пам'яті, що адресується;</li><li>наявністю або відсутністю вбудованого графічного ядра;</li><li>енергоспоживанням.</li></ul>
				<p>Спрощена структурна схема сучасного многоядерного процесора представлена на малюнку 1.</p>
				<figure>
					<a href="../add/cp_001b.html"><img src="../img/cp_001b.png" alt="" height="680px" width="680px"></a>
					<figcaption>Рисунок 1. Спрощена структурна схема процесора<br>(натисніть для збільшення)</figcaption>
				</figure>
				<h2><a name="2"></a>2. Ядро процесора</h2>
				<p>Ядро процесора - це його основна частина, яка містить всі функціональні блоки і здійснює виконання всіх логічних і арифметичних операцій.</p>
				<p>На малюнку 1 наведена структурна схема пристрою ядра процесора. Як видно на малюнку, кожне ядро процесора складається з декількох функціональних блоків:</p>
				<ul class="ul"><li>блоку вибірки інструкцій;</li><li>блоків декодування інструкцій;</li><li>блоків вибірки даних;</li><li>керуючого блоку;</li><li>блоків виконання інструкцій;</li><li>блоків збереження результатів;</li><li>блоки роботи з перериваннями;</li><li>ПЗУ, що містить мікрокод;</li><li>набору регістрів;</li><li>лічильника команд.</li></ul>
				<p><b>Блок вибірки інструкцій</b> здійснює зчитування інструкцій за адресою, вказаною в лічильнику команд. Зазвичай, за такт він зчитує кілька інструкцій. Кількість зчитувальних інструкцій обумовлено кількістю блоків декодування, так як необхідно на кожному такті роботи максимально завантажити блоки декодування. Для того щоб блок вибірки інструкцій працював в оптимальному режимі, в ядрі процесора є провісник переходів.</p>
				<p><b>Провісник переходів</b> намагається визначити, яка послідовність команд буде виконуватися після скоєння переходу. Це необхідно, щоб після умовного переходу максимально навантажити конвеєр ядра процесора.</p>
				<p><b>Блоки декодування</b>, як зрозуміло з назви, - це блоки, які займаються декодуванням інструкцій, тобто визначають, що треба зробити процесору, і які додаткові дані потрібні для виконання інструкції. Завдання це для більшості сучасних комерційних процесорів, побудованих на базі концепції CISC, - дуже складне. Справа в тому, що довжина інструкцій і кількість операндів - нефіксовані, і це сильно ускладнює життя розробникам процесорів і робить процес декодування нетривіальним завданням.</p>
				<p>Часто окремі складні команди доводиться замінювати мікрокодом - серією простих інструкцій, які в сукупності виконують ту саму дію, що і одна складна інструкція. Набір микрокода прошитий в ПЗУ, вбудованому в процесорі. До того ж мікрокод спрощує розробку процесора, так як відпадає потреба в створенні складних блоків ядра для виконання окремих команд, та і виправити мікрокод набагато простіше, ніж усунути помилку в функціонуванні блоці.</p>
				<p>У сучасних процесорах, зазвичай, буває 2-4 блока декодування інструкцій, наприклад, в процесорах Intel Core 2 кожне ядро містить по два таких блоків.</p>
				<p><b>Блоки вибірки даних</b> здійснюють вибірку даних з КЕШ-пам'яті або ОЗУ, необхідних для виконання поточних інструкцій. Зазвичай, кожне процесорний ядро містить кілька блоків вибірки даних. Наприклад, в процесорах Intel Core використовується по два блоки вибірки даних для кожного ядра.</p>
				<p><b>Керуючий блок</b> на підставі декодованих інструкцій управляє роботою блоків виконання інструкцій, розподіляє навантаження між ними, забезпечує своєчасне і правильне виконання інструкцій. Це один з найбільш важливих блоків ядра процесора.</p>
				<p><b>Блоки виконання інструкцій</b> включають в себе кілька різнотипних блоків:</p>
				<p>ALU - арифметичний логічний пристрій;</p>
				<p>FPU - пристрій по виконанню операцій з плаваючою точкою;</p>
				<p>Блоки для обробки розширення наборів інструкцій. Додаткові інструкції використовуються для прискорення обробки потоків даних, шифрування і дешифрування, кодування відео і так далі. Для цього в ядро процесора вводять додаткові регістри та набори логіки. На даний момент найбільш популярними розширеннями наборів інструкція є:</p>
				<p>MMX (Multimedia Extensions) - набір інструкцій, розроблений компанією Intel, для прискорення кодування і декодування потокових аудіо і відео-даних;</p>
				<p>SSE (Streaming SIMD Extensions) - набір інструкцій, розроблений компанією Intel, для виконання однієї і тієї ж послідовності операцій над безліччю даних з розпаралелюванням обчислювального процесу. Набори команд постійно удосконалюються, і на даний момент є ревізії: SSE, SSE2, SSE3, SSSE3, SSE4;</p>
				<p>ATA (Application Targeted Accelerator) - набір інструкцій, розроблений компанією Intel, для прискорення роботи спеціалізованого програмного забезпечення і зниження енергоспоживання при роботі з такими програмами. Ці інструкції можуть використовуватися, наприклад, при розрахунку контрольних сум або пошуку даних;</p>
				<p>3DNow - набір інструкцій, розроблений компанією AMD, для розширення можливостей набору інструкцій MMX;</p>
				<p>AES (Advanced Encryption Standard) - набір інструкцій, розроблений компанією Intel, для прискорення роботи додатків, що використовують шифрування даних за однойменним алгоритмом.</p>
				<p><b>Блок збереження результатів</b> забезпечує запис результату виконання інструкції в ОЗУ за адресою, вказаною в оброблюваної інструкції.</p>
				<p><b>Блок роботи з перериваннями.</b> Робота з перериваннями - одна з найважливіших задач процесора, що дозволяє йому своєчасно реагувати на події, переривати хід роботи програми і виконувати необхідні від нього дії. Завдяки наявності переривань, процесор здатний до псевдопараллельної роботи, тобто до, так званої, багатозадачності.</p>
				<p>Обробка переривань відбувається наступним чином. Процесор перед початком кожного циклу роботи перевіряє наявність запиту на переривання. Якщо є переривання для обробки, процесор зберігає в стек адреса інструкції, яку він повинен був виконати, і дані, отримані після виконання останньої інструкції, і переходить до виконання функції обробки переривання.</p>
				<p>Після закінчення виконання функції обробки переривання, з стека зчитуються збережені в нього дані, і процесор відновлює виконання відновленої завдання.</p>
				<p><b>Регістри</b> - надшвидка оперативна пам'ять (доступ до регістрів в кілька разів швидше доступу до КЕШ-пам'яті) невеликого обсягу (кілька сотень байт), що входить до складу процесора, для тимчасового зберігання проміжних результатів виконання інструкцій. Регістри процесора діляться на два типи: регістри загального призначення і спеціальні регістри.</p>
				<p>Регістри загального призначення використовуються при виконанні арифметичних і логічних операцій, або специфічних операцій додаткових наборів інструкцій (MMX, SSE і т.д.).</p>
				<p>Регістри спеціального призначення містять системні дані, необхідні для роботи процесора. До таких регістрів належать, наприклад, регістри управління, регістри системних адрес, регістри налагодження і т.д. Доступ до цих регістрів жорстко регламентований.</p>
				<p><b>Лічильник команд</b> – регістр, що містить адресу команди, яку процесор почне виконувати на наступному такті роботи.</p>
				<h2><a name="2.1"></a>2.1 Принцип роботи ядра процесора</h2>
				<p>Принцип роботи ядра процесора заснований на циклі, описаному ще Джоном фон Нейманом в 1946 году. У спрощеному вигляді етапи циклу роботи ядра процесора можна представити таким чином:</p>
				<p class="mar40">1. Блок вибірки інструкцій перевіряє наявність переривань. Якщо переривання є, то дані регістрів і лічильника команд заносяться в стек, а в лічильник команд заноситься адреса команди обробника переривань. По закінченню роботи функції обробки переривань, дані з стека будуть поновлені;</p>
				<p class="mar40">2. Блок вибірки інструкцій з лічильника команд зчитує адресу команди, призначеної для виконання. За цією адресою з КЕШ-пам'яті або ОЗУ зчитується команда. Отримані дані передаються в блок декодування;</p>
				<p class="mar40">3. Блок декодування команд розшифровує команду, при необхідності використовуючи для інтерпретації команди записаний в ПЗП мікрокод. Якщо це команда переходу, то в лічильник команд записується адреса переходу і управління передається в блок вибірки інструкцій (пункт 1), інакше лічильник команд збільшується на розмір команди (для процесора з довгою команди 32 біта - на 4) і передає управління в блок вибірки даних ;</p>
				<p class="mar40">4. Блок вибірки даних зчитує з КЕШ-пам'яті або ОЗУ необхідні для виконання команди дані і передає управління планувальником;</p>
				<p class="mar40">5. Керуючий блок визначає, якого блоку виконання інструкцій обробити поточну задачу, і передає управління цього блоку;</p>
				<p class="mar40">6. Блоки виконання інструкцій виконують необхідні командою дії і передають управління блоку збереження результатів;</p>
				<p class="mar40">7. При необхідності збереження результатів в ОЗУ, блок збереження результатів виконує необхідні для цього дії і передає управління блоку вибірки інструкцій (пункт 1).</p>
				<p>Описаний вище цикл називається процесом (саме тому процесор називається процесором). Послідовність виконуваних команд називається програмою.</p>
				<p>Швидкість переходу від одного етапу циклу до іншого визначається тактовою частотою процесора, а час роботи кожного етапу циклу і час, що витрачається на повне виконання однієї інструкції, визначається пристроєм ядра процесора.</p>
				<h2><a name="2.2"></a>2.2. Методи покращення роботи ядра процесора</h2>
				<p>Збільшення продуктивності ядра процесора, за рахунок підняття тактової частоти, має жорстке обмеження. Збільшення тактової частоти тягне за собою підвищення температури процесора, енергоспоживання і зниження стабільності його роботи і терміну служби.</p>
				<p>Тому розробники процесорів застосовують різні архітектурні рішення, що дозволяють збільшити продуктивність процесорів без збільшення тактової частоти.</p>
				<p>Розглянемо основні способи підвищення продуктивності процесорів.</p>
				<h4><a name="2.2.1"></a>2.2.1. Конвеєрізація</h4>
				<p>Кожна інструкція, яка виконується процесором, послідовно проходить всі блоки ядра, в кожному з яких відбувається своя частина дій, необхідних для виконання інструкції. Якщо приступати до обробки нової інструкції тільки після завершення роботи над першою інструкцією, то велика частина блоків ядра процесора в кожен момент часу буде простоювати, а, отже, можливості процесора будуть використовуватися в повному обсязі.</p>
				<p>Розглянемо приклад, в якому процесор буде виконувати програму, що складається з п'яти інструкцій (К1-К5), без використання принципу конвейеризации. Для спрощення прикладу візьмемо, що кожен блок ядра процесора виконує інструкцію за 1 такт.</p>
				<table class="table1">
					<tr>
						<td>Такти</td> 
						<td>Вибірка інструкцій</td> 
						<td>Декодування інструкції</td> 
						<td>Вибірка даних</td> 
						<td>Виконання інструкції</td> 
						<td>Збереження результата</td>
					</tr>
					<tr>
						<td>1</td>
						<td>K1</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
					</tr>
					<tr>
						<td>2</td>
						<td>-</td> 
						<td>K1</td> 
						<td>-</td> 
						<td>-</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>3</td> 
						<td>-</td> 
						<td>-</td> 
						<td>K1</td> 
						<td>-</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>4</td> 
						<td>-</td> 
						<td>-</td> 
						<td>-</td> 
						<td>K1</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>5</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>K1</td>
					</tr>
					<tr>
						<td>6</td>
						<td>K2</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
					</tr>
					<tr>
						<td>7</td>
						<td>-</td> 
						<td>K2</td> 
						<td>-</td> 
						<td>-</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>8</td> 
						<td>-</td> 
						<td>-</td> 
						<td>K2</td> 
						<td>-</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>9</td> 
						<td>-</td> 
						<td>-</td> 
						<td>-</td> 
						<td>K2</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>10</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>K2</td>
					</tr>
					<tr>
						<td>11</td>
						<td>K3</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
					</tr>
					<tr>
						<td>12</td>
						<td>-</td> 
						<td>K3</td> 
						<td>-</td> 
						<td>-</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>13</td> 
						<td>-</td> 
						<td>-</td> 
						<td>K3</td> 
						<td>-</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>14</td> 
						<td>-</td> 
						<td>-</td> 
						<td>-</td> 
						<td>K3</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>15</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>K3</td>
					</tr>
					<tr>
						<td>16</td>
						<td>K4</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
					</tr>
					<tr>
						<td>17</td>
						<td>-</td> 
						<td>K4</td> 
						<td>-</td> 
						<td>-</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>18</td> 
						<td>-</td> 
						<td>-</td> 
						<td>K4</td> 
						<td>-</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>19</td> 
						<td>-</td> 
						<td>-</td> 
						<td>-</td> 
						<td>K4</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>20</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>K4</td>
					</tr>
					<tr>
						<td>21</td>
						<td>K5</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
					</tr>
					<tr>
						<td>22</td>
						<td>-</td> 
						<td>K5</td> 
						<td>-</td> 
						<td>-</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>23</td> 
						<td>-</td> 
						<td>-</td> 
						<td>K5</td> 
						<td>-</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>24</td> 
						<td>-</td> 
						<td>-</td> 
						<td>-</td> 
						<td>K5</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>25</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>K5</td>
					</tr>
				</table>
				<p>Як видно з таблиці, для виконання п'яти інструкцій процесору знадобилося 25 тактів. При цьому в кожному такті чотири з п'яти блоків ядра процесора простоювали, тобто процесор використовував всього 20% свого потенціалу. Звісно, в реальних процесорах все складніше. Різні блоки процесора вирішують різні за складністю завдання. Самі інструкції теж відрізняються один від одного за складністю. Але в загальному ситуація залишається такою ж.</p>
				<p>Для вирішення цієї проблеми у всіх сучасних процесорах виконання інструкцій побудовано за принципом конвеєра, тобто в міру звільнення блоків ядра, вони завантажуються обробкою наступної інструкції, не чекаючи поки попередня інструкція виконається повністю.</p>
				<p>Розглянемо приклад виконання тієї ж програми, що складається з п'яти інструкцій, але з використанням принципу конвейеризации.</p>
				<table class="table1">
					<tr>
						<td>Такти</td> 
						<td>Вибірка інструкцій</td> 
						<td>Декодування інструкції</td> 
						<td>Вибірка даних</td> 
						<td>Виконання інструкції</td> 
						<td>Збереження результата</td>
					</tr>
					<tr>
						<td>1</td>
						<td>K1</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
						<td>-</td>
					</tr>
					<tr>
						<td>2</td>
						<td>К2</td> 
						<td>K1</td> 
						<td>-</td> 
						<td>-</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>3</td> 
						<td>К3</td> 
						<td>К2</td> 
						<td>K1</td> 
						<td>-</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>4</td> 
						<td>К4</td> 
						<td>К3</td> 
						<td>К2</td> 
						<td>K1</td> 
						<td>-</td>
					</tr>
					<tr>
						<td>5</td>
						<td>К5</td>
						<td>К4</td>
						<td>К3</td>
						<td>К2</td>
						<td>K1</td>
					</tr>
					<tr>
						<td>6</td>
						<td>-</td>
						<td>К5</td>
						<td>К4</td>
						<td>К3</td>
						<td>К2</td>
					</tr>
					<tr>
						<td>7</td>
						<td>-</td> 
						<td>-</td> 
						<td>К5</td> 
						<td>К4</td> 
						<td>К3</td>
					</tr>
					<tr>
						<td>8</td> 
						<td>-</td> 
						<td>-</td> 
						<td>-</td> 
						<td>К5</td> 
						<td>К4</td>
					</tr>
					<tr>
						<td>9</td> 
						<td>-</td> 
						<td>-</td> 
						<td>-</td> 
						<td>-</td> 
						<td>К5</td>
					</tr>
				</table>
				<p>Та ж програма була виконана за 9 тактів, що майже 2.8 рази швидше, ніж при роботі без конвеєра. Як видно з таблиці максимальне завантаження процесора була отримана на 5 такті. У цей момент використовувалися всі блоки ядра процесора. А з першого по четвертий такт, включно, відбувалося наповнення конвеєра.</p>
				<p>Так як процесор виконує команди безперервно, то, в ідеалі, він міг би бути зайнятий на 100%, при цьому, чим довше був би конвеєр, тим більший виграш в продуктивності був би отриманий. Але на практиці це не так.</p>
				<p>По-перше, реальний потік команд, що обробляється процесором - непослідовний. У ньому часто зустрічаються переходи. При цьому поки команда умовного переходу НЕ буде оброблена повністю, конвеєр не зможе почати виконання нової команди, тому що не знає, за якою адресою вона знаходиться.</p>
				<p>Після умовного переходу конвеєр доводиться наповнювати заново. І чим довше конвеєр, тим довше це відбувається. В результаті, приріст продуктивності від введення конвеєра знижується.</p>
				<p>Для зменшення впливу умовних переходів на роботу конвеєра, в ядро процесора вводяться блоки передбачення умовних переходів. Основне завдання цих блоків - визначити, коли буде здійснений умовний перехід і які команди будуть виконані після здійснення умовного переходу.</p>
				<p>Якщо умовний перехід вдалося передбачити, то виконання інструкцій за новою адресою починається раніше, ніж буде закінчена обробка команди умовного переходу. В результаті, наповнення конвеєра не постраждає.</p>
				<p>За статистикою, точність блоків передбачення умовних переходів в сучасних процесорах перевищує 90%, що дозволяє робити досить довгі, але при цьому добре наповнюються конвеєри.</p>
				<p>По-друге, часто оброблювані інструкції - взаємопов'язані, тобто одна з інструкцій вимагає в якості вихідних даних результату виконання іншої інструкції.</p>
				<p>В цьому випадку вона може бути виконана тільки після повного завершення обробки першої інструкції. Однак сучасні процесори можуть аналізувати код на кілька інструкцій вперед і, наприклад, паралельно з першою інструкцією обробити третю інструкцію, яка ніяк не залежить від перших двох.</p>
				<p>У більшості сучасних процесорах завдання аналізу взаємозв'язку інструкцій і складання порядку їх обробки лягає на плечі процесора, що неминуче веде до зниження його швидкодії і збільшення вартості.</p>
				<p>Однак все більшої популярності отримує статичне планування, коли порядок виконання програми процесором визначається на етапі компіляції програми. У цьому випадку інструкції, які можна виконати паралельно, об'єднуються компілятором в одну довгу команду, в якій всі інструкції свідомо паралельні. Процесори, що працюють з такими інструкціями, побудовані на базі архітектура VLIW (Very long instruction word).</p>
				<h4><a name="2.2.2"></a>2.2.2. Суперскалярность</h4>
				<p>Суперскалярність - архітектура обчислювального ядра, при якій найбільш навантажені блоки можуть входити в декількох примірниках. Скажімо, в ядрі процесора блок вибірки інструкцій може навантажувати відразу кілька блоків декодування.</p>
				<p>В цьому випадку блоки, виконують більш складні дії і працюють довше, за рахунок паралельної обробки відразу декількох інструкцій не будуть затримувати весь конвеєр.</p>
				<p>Однак паралельне виконання інструкцій можливо, тільки якщо ці інструкції - незалежні.</p>
				<p>Структурна схема ядра конвеєра гіпотетичного процесора, побудованого з використанням принципу суперскалярного, наведена на малюнку 1. На цьому малюнку в кожному ядрі процесора працює кілька блоків декодування, кілька блоків вибірки даних і кілька блоків виконання інструкцій.</p>
				<h4><a name="2.2.3"></a>2.2.3. Параллельная обработка данных</h4>
				<p>Нескінченно підвищувати продуктивність процесорів, за рахунок збільшення тактової частоти, неможливо. Збільшення тактової частоти тягне за собою збільшення тепловиділення, зменшення терміну служби і надійності роботи процесорів, так і затримки від звернення до пам'яті сильно знижують ефект від збільшення тактової частоти. Дійсно, зараз практично не зустрінеш процесори з тактовою частотою вище 3.8 ГГц.</p>
				<p>Пов'язані зі збільшенням тактової частоти проблеми змушують розробників шукати інші шляхи підвищення продуктивності процесорів. Один з найбільш популярних способів - паралельні обчислення.</p>
				<p>Переважна більшість сучасних процесорів мають два і більше ядра. Топові моделі можуть містити і 8, і навіть 12 ядер, причому з підтримкою технології hyper-threading. Переваги від введення додаткових ядер цілком зрозумілі, ми практично отримуємо кілька процесорів, здатних незалежно вирішувати кожен свої завдання, при цьому, природно, зростає продуктивність. Однак приріст продуктивності далеко не завжди виправдовує очікування.</p>
				<p>По-перше, далеко не всі програми підтримують розподіл обчислень на кілька ядер. Природно, можна програми розділяти між ядрами, щоб на кожному ядрі працював свій набір незалежних програм. Наприклад, на одному ядрі працює операційна система з набором службових програм, на іншому призначені для користувача програми і так далі.</p>
				<p>Але це дає виграш в продуктивності до тих пір, поки не з'являється програма, яка потребує ресурсів більше, ніж може дати одне ядро. Добре, якщо вона підтримує розподіл навантаження між декількома ядрами. Але на даний момент загальнодоступних програм, здатних розподілити навантаження між 12 ядерами, та ще в режимі Hyper-Threading, можна «порахувати на пальцях однієї руки». Існують програми, оптимізовані для багатопоточних обчислень, але більшості простих користувачів вони не потрібні. А ось найбільш популярні програми, а тим більше ігри, поки що «погано» адаптуються до багатоядерних процесорів, особливо, якщо кількість ядер більше чотирьох.</p>
				<p>По-друге, ускладнюється робота з пам'яттю, так як ядер - багато, і всім їм потрібен доступ до ОЗУ. Потрібно складний механізм, що визначає черговість доступу ядер процесора до пам'яті та до інших ресурсів ЕОМ.</p>
				<p>По-третє, зростає енергоспоживання, а, отже, збільшується тепловиділення і потрібна потужна система охолодження.</p>
				<p>Ну і, по-четверте, собівартість виробництва багатоядерних процесорів - немаленька, а, відповідно, і ціна на такі процесори «кусається».</p>
				<p>Незважаючи на всі недоліки, застосування процесорів з 2-4 ядрами, безсумнівно, дає значний приріст продуктивності. Однак, на даний момент, застосування процесорів з кількістю ядер більше чотирьох не завжди виправдовує очікування. Однак, в найближчому майбутньому, ситуація повинна кардинально змінитися. Обов'язково з'явиться безліч програм з підтримкою багатопоточності, продуктивність окремих ядер зросте, а їхня ціна знизиться.</p>
				<h4><a name="2.2.4"></a>2.2.4. Технологія Hyper-Threading</h4>
				<p>Технологія Intel Hyper-threading дозволяє кожному ядру процесора виконувати два завдання одночасно, по суті, роблячи з одного реального ядра два віртуальних. Це можливо через те, що в таких ядрах зберігається стан відразу двох потоків, так як у ядра є свій набір регістрів, свій лічильник команд і свій блок роботи з перериваннями для кожного потоку. В результаті, операційна система бачить таке ядро, як два окремих ядра, і буде з ними працювати так само, як працювала б з двоядерним процесором.</p>
				<p>Однак інші елементи ядра для обох потоків - загальні, і діляться між ними. Крім цього, коли з якої-небудь причини один з потоків звільняє елементи конвеєра, інший потік використовує вільні блоки.</p>
				<p>Елементи конвеєра можуть бути не задіяні, якщо, наприклад, стався промах при зверненні в КЕШ-пам'ять, і необхідно вважати дані з ОЗУ, або невірно був передбачений перехід, або очікуються результати обробки поточної інструкції, або якісь блоки взагалі не використовуються при обробці даної інструкції і т.д.</p>
				<p>Більшість програм не можуть повністю навантажити процесор, так як деякі, в основному, використовують нескладні цілочисельні обчислення, практично не задіюючи блок FPU. Інші ж програми, наприклад 3D-студія, вимагають масу розрахунків з використанням чисел з плаваючою точкою, але при цьому звільняючи деякі інші виконавчі блоки і так далі.</p>
				<p>До того ж практично у всіх програмах - багато умовних переходів і залежних змінних. В результаті, використання технології Hyper-threading може дати істотний приріст продуктивності, сприяючи максимальному завантаженні конвеєра ядра.</p>
				<p>Але не все так просто. Природно, приріст продуктивності буде менше, ніж від використання декількох фізичних ядер, так як все-таки потоки використовують загальні блоки одного конвеєра і часто змушені чекати звільнення необхідного блоку. До того ж більшість процесорів вже мають кілька фізичних ядер, і при використанні технології Hyper-threading віртуальних ядер може стати занадто багато, особливо, якщо процесор містить чотири і більше фізичних ядра.</p>
				<p>Так як на даний момент програм, здатних розподіляти обчислення на велику кількість ядер, - вкрай мало, то в цьому випадку результат може розчарувати користувачів.</p>
				<p>Є ще одна серйозна проблема технології Hyper-Threading - це конфлікти, що виникають, коли інструкції різних потоків потребують однотипних блоках. Може скластися ситуація, коли паралельно працюватимуть два схожих потоку, часто використовують одні і ті ж блоки. В такому випадку приріст продуктивності буде мінімальний.</p>
				<p>В результаті, технологія Hyper-Threading дуже залежна від типу навантаження на процесор і може дати хороший приріст продуктивності, а може бути практично даремною.</p>
				<h4><a name="2.2.5"></a>2.2.5. Технологія Turbo Boost</h4>
				<p>Продуктивність більшості сучасних процесорів в домашніх умовах можна трохи підняти, просто кажучи розігнати - змусити працювати на частотах, що перевищують номінальну, тобто заявлену виробником.</p>
				<p>Частота процесора розраховується, як частота системної шини, помножена на якийсь коефіцієнт, званий множником. Наприклад, процесор Core i7-970 працює з системною шиною DMI на базовій частоті - 133 МГц, і має множник - 24. Таким чином, тактова частота ядра процесора складе: 133 Мгц * 24 = 3192 Мгц.</p>
				<p>Якщо в налаштуваннях BIOS збільшити множник або підняти тактову частоту системної шини, то тактова частота процесора збільшиться, а, відповідно, збільшиться і його продуктивність. Однак процес цей - далеко небезпечний. Через розгону процесор може працювати нестабільно або взагалі вийти з ладу. Тому до розгону потрібно підходити відповідально і ретельно контролювати параметри роботи процесора.</p>
				<p>З поява технології Turbo Boost все стало набагато простіше. Процесори з цією технологією можуть самі динамічно, на короткий проміжок часу, підвищувати тактову частоту, тим самим, збільшуючи свою продуктивність. При цьому процесор контролює всі параметри своєї роботи: напруга, силу струму, температуру і т.д., не допускаючи збоїв і тим більше виходу з ладу. Наприклад, процесор може вимикайте ядра, тим самим, знизивши загальну температуру, а натомість збільшити тактову частоту інших ядер.</p>
				<p>Так як на даний момент існує не дуже багато програм, що використовують для обробки даних все процесорні ядра, особливо, якщо їх більше чотирьох, то застосування технології Turbo Boost дозволяє значно підняти продуктивність процесора, особливо, при роботі з однопоточні додатками.</p>
				<h4><a name="2.2.6"></a>2.2.6. Ефективність виконання команд</h4>
				<p>Залежно від типів оброблюваних інструкцій і способу їх виконання, процесори поділяються на кілька груп:</p>
				<ul class="ul"><li>на класичні процесори CISC;</li><li>на процесори RISC зі скороченим набором команд;</li><li>на процесори MISC c мінімальним набором команд;</li><li>на процесори VLIW з набором наддовгих команд.</li></ul>
				<p><b>CISC (Complex instruction set computer)</b> - це процесори зі складним набором команд. Архітектура CISC характеризується:</p>
				<ul class="ul"><li>складними і багатоплановими інструкціями;</li><li>великим набором різних інструкцій;</li><li>нефіксованою довжиною інструкцій;</li><li>різноманіттям режимів адресації.</li></ul>
				<p>Історично, процесори з архітектурою CISC з'явилися першими, і їх поява була обумовлена загальною тенденцією розробки перших ЕОМ. ЕОМ прагнули зробити більш функціональними і в той же час простими для програмування. Природно, для програмістів спочатку було зручніше мати широкий набір команд, ніж реалізовувати кожну функцію цілої окремої підпрограмою. В результаті, обсяг програм сильно скорочувався, а разом з ним і трудомісткість програмування.</p>
				<p>Однак така ситуація тривала недовго. По-перше, з появою мов високого рівня відпала необхідність безпосереднього програмування в машинних кодах і на асемблері, і, по-друге, з часом кількість різних команд сильно зросла, а самі інструкції ускладнилися. В результаті, більшість програмістів, в основному, використовували якийсь певний набір інструкцій, практично ігноруючи найбільш складні інструкції.</p>
				<p>В результаті, програмісти вже не мали особливої вигоди від широкого набору інструкцій, так як компіляція програм стала автоматичною, а самі процесори обробляли складні і різноманітні інструкції повільно, в основному, через проблеми з їх декодуванням.</p>
				<p>До того ж нові складні інструкції розробники процесорів налагоджували менше, так як це був трудомісткий і складний процес. В результаті, деякі з них могли містити помилки.</p>
				<p>Ну і, природно, чим складніше інструкції, чим більше дій вони виконують, тим складніше їх виконання распарелювати, і, відповідно, тим менш ефективно вони завантажують конвеєр процесора.</p>
				<p>Проте до цього моменту вже було розроблено величезну кількість програм для процесорів з CISC архітектурою, тому економічно було невигідно переходити на принципово нову архітектуру, навіть дає виграш в продуктивності процесора.</p>
				<p>Тому було прийнято компроміс, і CISC процесори, починаючи з Intel486DX, стали виробляти з використанням RISC-ядра. Тобто, безпосередньо перед виконанням, складні CISC-інструкції перетворять в більш простий набір внутрішніх інструкцій RISC. Для цього використовують записані в розміщеному всередині ядра процесора ПЗУ набори мікрокоманд - серії простих інструкцій, які в сукупності виконують ті ж дії, що і одна складна інструкція.</p>
				<p><b>RISC (Reduced Instruction Set Computer)</b> - процесори зі скороченим набором інструкцій.</p>
				<p>У концепції RISC-процесорів перевага віддається коротким, простим і стандартизованим інструкціям. В результаті, такі інструкції простіше декодувати і виконувати, а, отже, пристрій процесора стає так само простіше, так як не потрібно складних блоків для виконання нестандартних і багатофункціональних інструкцій. В результаті, процесор стає дешевше, і з'являється можливість додатково підняти його тактову частоту, за рахунок спрощення внутрішньої структури і зменшення кількості транзисторів, або знизити енергоспоживання.</p>
				<p>Так само прості RISC-інструкції набагато простіше распаралелювати, ніж CISC-інструкції, а, отже, з'являється можливість більше завантажити конвеєр, ввести додаткові блоки обробки інструкцій і т.д.</p>
				<p>Процесори, побудовані по архітектурі RISC, володіють наступними основними особливостями:</p>
				<ul class="ul"><li>фіксована довжина інструкцій;</li><li>невеликий набір стандартизованих інструкцій;</li><li>велика кількість регістрів загального призначення;</li><li>відсутність мікрокода;</li><li>менше енергоспоживання, в порівнянні з CISC-процесорами аналогічної продуктивності;</li><li>простіше внутрішній устрій;</li><li>менша кількість транзисторів, в порівнянні з CISC-процесорами аналогічної продуктивності;</li><li>відсутність складних спеціалізованих блоків в ядрі процесора.</li></ul>
				<p>В результаті, хоча RISC-процесори і вимагають виконання більшої кількості інструкцій для вирішення однієї і тієї ж задачі, в порівнянні з CISС-процесорами, вони, в загальному випадку, показують більш високу продуктивність. По-перше, виконання однієї RISC-інструкції займає набагато менше часу, ніж виконання CISC-інструкції. По-друге, RISC-процесори більш широко використовують можливості паралельної роботи. По-третє, RISC-процесори можуть мати більш високу тактову частоту, в порівнянні з CISC-процесорами.</p>
				<p>Однак, незважаючи на явну перевагу RISC, процесори не отримали такого серйозного поширення, як CISC. Правда, пов'язано це в основному не з тим, що вони з якихось параметрах могли бути гірше CISC-процесорів. Вони не гірше. Справа в тому, що СISC-процесори з'явилися першими, а програмне забезпечення для CISC-процесорів - несумісне з RISC-процесорами.</p>
				<p>В результаті, економічно вкрай невигідно переписувати всі програми, які вже розроблені, налагоджені і використовуються величезною кількістю користувачів. Ось так і вийшло, що тепер ми змушені використовувати CISC-процесори. Правда, як я вже говорив, розробники знайшли компромісне рішення даної проблеми, і вже дуже давно в CISC-процесорах використовують RISC-ядро і заміну складних команд на прошивки. Це дозволило дещо згладити ситуацію. Але все ж RISC-процесори за більшістю параметрів виграють навіть у CISC-процесорів з RISC-ядром.</p>
				<p><b>MISC (Minimal Instruction Set Computer)</b> - подальший розвиток архітектури RISС, заснований на ще більшому спрощенні інструкцій і зменшенні їх кількості. Так, в середньому, в MISC-процесорах використовується 20-30 простих інструкцій. Такий підхід дозволив ще більше спростити пристрій процесора, знизити енергоспоживання і максимально використовувати можливості паралельної обробки даних.</p>
				<p><b>VLIW (Very long instruction word)</b> - архітектура процесорів, що використовує інструкції великої довжини, що містять відразу кілька операцій, об'єднаних компілятором для паралельної обробки. У деяких реалізаціях процесорів довжина інструкцій може досягати 128 або навіть 256 біт.</p>
				<p>Архітектура VLIW є подальшим удосконаленням архітектури RISC і MISC з поглибленим паралелізмом.</p>
				<p>Якщо в процесорах з RISC організацією паралельною обробкою даних займався сам процесор, при цьому, витрачаючи частину ресурсів на аналіз інструкцій, виявлення залежностей і передбачення умовних переходів (причому, найчастіше, процесор міг помилятися, наприклад, в прогнозі умовних переходів, тим самим вносячи серйозні затримки в обробку інструкцій, або переглядати код програми на недостатню глибину для виявлення незалежних операцій, які могли б виконуватися паралельно), то в VLIW-процесорах завдання оптимізації паралельної роботи покладалася на компілятор, який не був обмежений ні в часі, ні в ресурсах і міг проаналізувати всю програму для складання оптимального для роботи процесора коду.</p>
				<p>В результаті, процесор VLIW вигравав не тільки від скасування накладних витрат на організацію паралельної обробки даних, а й отримував приріст продуктивності, через більш оптимальної організації паралельного виконання інструкцій.</p>
				<p>Крім цього спрощувалася конструкція процесора, так як спрощувались або зовсім скасовувалися деякі блоки, які відповідають за аналіз залежностей і організацію розпаралелювання обробки інструкцій, а це, в свою чергу, вело до зниження енергоспоживання і собівартості процесорів.</p>
				<p>Однак навіть компілятору важко справлятися з аналізом коду і організацією його розпаралелювання. Часто код програми був сильно взаємозалежний, і, в результаті, в інструкції компілятору доводилося вставляти порожні команди. Через це програми для VLIW-процесорів могли бути набагато довший, ніж аналогічні програми для традиційних архітектур.</p>
				<p>Перші VLIW-процесори з'явилися в кінці 1980-х років і були розроблені компанією Cydrome. Так само до процесорів з цієї архітектурою відносяться процесори TriMedia фірми Philips, сімейство DSP C6000 фірми Texas Instruments, Ельбру? З 2000 - процесор російського виробництва, розроблений компанією МЦСТ за участю студентів МФТІ та ін. Підтримка довгих інструкцій з явним паралелізмом є і в процесорах сімейства Itanium.</p>
				<h4><a name="2.3"></a>2.3. Способи зниження енергоспоживання процесора</h4>
				<p>Не менш, ніж продуктивність, для процесора важливий і такий параметр, як енергоспоживання. Особливо гостро питання енергоспоживання встав зараз, коли спостерігається справжній бум популярності портативних пристроїв.</p>
				<p>Час автономної роботи цих пристроїв безпосередньо залежить від їх енергоспоживання, і чимала частка енергоспоживання припадає на процесор. Для зниження енергоспоживання процесорів використовуються різні способи і технології. Давайте розглянемо найбільш популярні з них.</p>
				<p>Найпростіший спосіб знизити енергоспоживання і тепловиділення процесора - це зменшити його тактову частоту і напругу, так як енергоспоживання процесора пропорційно квадрату його робочої напруги і пропорційно тактовій частоті. Найбільш вигідно на енергоспоживанні позначається зниження напруги. Однак при зниженні напруги рано чи пізно зменшується і тактова частота, що природно спричинить за собою зниження продуктивності.</p>
				<p>Однак, найчастіше, енергоспоживання буває більш критичним параметром роботи, і деяке зниження продуктивності допустимо. Так більшість мобільних версій процесорів і процесорів для вбудованих систем мають тактову частоту і робоча напруга набагато нижче, ніж у їхніх побратимів для настільних версій.</p>
				<p>Але не завжди виробники встановлюють оптимальне поєднання напруги і тактової частоти. Багато мобільні процесори з встановленої тактовою частотою могли б працювати з більш низькою напругою, що дозволило б істотно продовжити час автономної роботи портативного комп'ютера.</p>
				<p>Для отримання оптимального співвідношення продуктивності до споживання електроенергії, необхідно підібрати таку напругу, при якому на заданій тактовій частоті процесор буде стабільно працювати.</p>
				<p>Тактова частота визначається, виходячи з потреб користувача, потім для неї підбирається мінімальна робоча напруга шляхом поступового зниження напруги і тестування процесора під навантаженням.</p>
				<p>Існують і не настільки кардинальні шляхи вирішення цієї проблеми.</p>
				<p>Наприклад, технологія EIST (Enhanced Intel SpeedStep Technology) дозволяє динамічно змінювати енергоспоживання процесора, за рахунок зміни тактової частоти процесора і напруги. Зміна тактової частоти відбувається, за рахунок зменшення або збільшення коефіцієнта множення.</p>
				<p>Тактова частота процесора розраховується, як тактова частота системної шини, помножена на якийсь коефіцієнт, званий коефіцієнтом множення. Зменшення або збільшення цього коефіцієнта веде до зменшення або збільшення тактової частоти процесора і до зниження або збільшення робочої напруги.</p>
				<p>У випадках, коли процесор використовується не повністю, його тактову частоту можна знизити, зменшуючи коефіцієнт множення. Як тільки користувачеві буде потрібно більше обчислювальних ресурсів, коефіцієнт множення буде підвищено, аж до свого номінального значення. Таким чином, вдається трохи знизити енергоспоживання.</p>
				<p>Аналогічна технологія для зменшення енергоспоживання, заснована на динамічній зміні напруги і тактової частоти, в залежності від навантаження на процесор, використовується і компанією AMD, називається вона - Cool'n'Quiet.</p>
				<p>В абсолютній більшості випадків обчислювальні машини або простоюють, або використовуються лише на частку своїх можливостей. Наприклад, для перегляду фільму або набору тексту зовсім не потрібно тих величезних обчислювальних можливостей, якими володіють сучасні процесори. Тим більше ці потужності не потрібні і коли комп'ютер не використовується, коли користувач відійшов або просто вирішив зробити невелику перерву. Знижуючи в такі моменти тактову частоту процесора і його напруга, можна отримати дуже серйозний приріст в економії енергоспоживання.</p>
				<p>Параметри роботи технології EIST можна налаштовувати, використовуючи BIOS і програмне забезпечення операційної системи, і встановлювати необхідні для конкретного випадку профілі управління енергоспоживанням, тим самим балансуючи продуктивність процесора і його енергоспоживання.</p>
				<p>Природно, розробники намагаються оптимізувати і саму структуру процесора для зниження енергоспоживання і можливості роботи процесора при наднизьких напружених. Однак це завдання - вкрай складне і трудомістке. Дослідні зразки процесорів вже практично впритул наблизилися до порога мінімального робочого напруги і вже насилу відрізняють напруга логічної одиниці від логічного нуля. Однак, незважаючи на це, розробники процесорів, в тому числі інженери корпорації Intel, обіцяють зменшити енергоспоживання сучасних процесорів аж в 100 разів за найближчі десять років.</p>
				<h2><a name="3"></a>3. Кеш-пам'ять</h2>
				<p>Незважаючи на всі технології та прийоми розробників, продуктивність процесора все-таки безпосередньо залежить від швидкості вибірки команд і даних з пам'яті. І навіть, якщо процесор має збалансований і продуманий конвеєр, використовує технологію Hyper-Threading і так далі, але не забезпечує належну швидкість вибірки даних і команд з пам'яті, то, в результаті, загальна продуктивність ЕОМ не виправдає ваших очікувань.</p>
				<p>Тому один з найважливіших параметрів пристрою процесора - це КЕШ-пам'ять, покликана скоротити час вибірки команд і даних з основної оперативної пам'яті і виконує роль проміжного буфера з швидким доступом між процесором і основною оперативною пам'яттю.</p>
				<p>Кеш-пам'ять будується на базі дорогої SRAM-пам'яті (static random access memory), що забезпечує доступ до осередків пам'яті набагато швидше, ніж до осередків DRAM-пам'яті (dynamic random access memory), на базі якої побудована оперативна пам'ять. До того ж SRAM-пам'ять не вимагає постійної регенерації, що так само збільшує її швидкодію.</p>
				<p>Кеш-пам'ять ділиться на кілька рівнів. У сучасних процесорах, зазвичай, буває три рівня, а в деяких топових моделях процесорів іноді зустрічається і чотири рівні КЕШ-пам'яті.</p>
				<p>Кеш-пам'ять більш високого рівня завжди більше за розміром і повільніше КЕШ-пам'яті нижчого рівня.</p>
				<p>Найшвидша і найменша КЕШ-пам'ять - це КЕШ-пам'ять першого рівня. Вона зазвичай працює на частоті процесора, має обсяг кілька сотень кілобайт і розташовується в безпосередній близькості від блоків вибірки даних і команд. При цьому вона може бути єдиною (Прінстонська архітектура) або розділятися на дві частини (Гарвардська архітектура): на пам'ять команд і пам'ять даних. У більшості сучасних процесорів використовують розділену КЕШ-пам'ять першого рівня, так як це дозволяє одночасно з вибіркою команд здійснювати вибірку даних, що вкрай важливо для роботи конвеєра.</p>
				<p>Кеш-пам'ять другого рівня - більш повільна (час доступу, в середньому, 8-20 тактів процесора), але зате має обсяг кілька мегабайт.</p>
				<p>Кеш-пам'ять третього рівня - ще повільніше, але має порівняно великий обсяг. Зустрічаються процесори з КЕШ-пам'яттю третього рівня більше 24 Мб.</p>
				<p>У багатоядерних процесорах, зазвичай, останній рівень КЕШ-пам'яті роблять загальним для всіх ядер. Причому, в залежності від навантаження на ядра, може динамічно змінюватися відведений ядру обсяг КЕШ-пам'яті останнього рівня. Якщо ядро має високе навантаження, то йому виділяється більше КЕШ-пам'яті, за рахунок зменшення обсягу КЕШ-пам'яті для менш навантажених ядер. Не всі процесори мають таку можливість, а тільки підтримують технологію Smart Cache (наприклад, Intel Smart Cache або AMD Balanced Smart Cache).</p>
				<p>Кеш-пам'ять нижчого рівня - зазвичай, індивідуальна для кожного ядра процесора.</p>
				<p>Процесор зчитує з основної оперативної пам'яті дані і заносить їх в КЕШ-пам'ять усіх рівнів, заміщаючи дані, до яких давно і найбільш рідко зверталися.</p>
				<p>Наступного разу, коли процесору знадобляться ці ж дані, вони будуть прочитані вже не з основної оперативної пам'яті, а з КЕШ-пам'яті першого рівня, що значно швидше. Якщо до цих даних процесор довго не буде звертатися, то вони будуть поступово витіснені з усіх рівнів КЕШ-пам'яті, спочатку з першого, так як він найменший за обсягом, потім з другого і так далі. Але, навіть якщо ці дані залишаться тільки в третьому рівні КЕШ-пам'яті, все одно звернення до них буде швидше, ніж до основної пам'яті.</p>
				<p>Однак, чим більше рівнів КЕШ-пам'яті, тим складніше алгоритм заміщення застарілих даних і тим більше часу витрачається на узгодження даних у всіх рівнях КЕШ-пам'яті. В результаті, виграш від швидкості роботи КЕШ-пам'яті швидко сходить нанівець. До того ж SRAM-пам'ять - дуже дорога, і при великих обсягах, а, як пам'ятаєте, кожен новий рівень КЕШ-пам'яті повинен бути більше попереднього, швидко знижується показник ціна-якість, що вкрай негативно позначається на конкурентоспроможності процесора. Тому на практиці більше чотирьох рівнів КЕШ-пам'яті не роблять.</p>
				<p>Ситуація з КЕШ-пам'яттю додатково ускладнюється в багатоядерних процесорах, кожне ядро ​​яких містить свою КЕШ-пам'ять. Необхідно вводити додаткову синхронізацію даних, що зберігаються в КЕШ-пам'яті різних ядер. Наприклад, один і той же блок даних основної оперативної пам'яті був занесений в КЕШ-пам'ять першого і другого ядра процесора. Потім перший процесор змінив цей блок пам'яті. Виходить, що в КЕШ-пам'яті другого процесора лежать вже застарілі дані і необхідно їх оновити, а це додаткове навантаження на КЕШ-пам'ять, що призводить до зниження загального швидкодії процесора. Ця ситуація тим складніше, чим більше ядер в процесорі, чим більше рівнів КЕШ-пам'яті і чим більше їх обсяг.</p>
				<p>Але, незважаючи на такі труднощі в роботі з КЕШ-пам'яттю, її застосування дає явний приріст швидкості роботи без істотного збільшення вартості ЕОМ. І поки не буде придумана оперативна пам'ять, яка зможе за швидкістю змагатися з SRAM-пам'яттю, а за ціною - з DRAM-пам'яті, буде застосовуватися ієрархічна організація оперативної пам'яті з використанням декількох рівнів КЕШ-пам'яті.</p>
			</div>	  
		</main>
		<footer class="footer"><div>© 2017 Боровик М.В.</div></footer>
	</div>
	<a href="#" class="scrollup">Scroll</a> 
</body>
</html>